2020-05-05 15:06:27,297 - INFO - allennlp.common.params - random_seed = 124
2020-05-05 15:06:27,297 - INFO - allennlp.common.params - numpy_seed = 1
2020-05-05 15:06:27,297 - INFO - allennlp.common.params - pytorch_seed = 12
2020-05-05 15:06:27,298 - INFO - allennlp.common.checks - Pytorch version: 1.4.0
2020-05-05 15:06:27,299 - INFO - allennlp.common.params - evaluate_on_test = True
2020-05-05 15:06:27,299 - INFO - allennlp.common.params - validation_dataset_reader = None
2020-05-05 15:06:27,299 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sent_per_example': '3', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '90', 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'pretrained_models/news_roberta_base/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'type': 'SeqClassificationReader', 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()
2020-05-05 15:06:27,300 - INFO - allennlp.common.params - dataset_reader.type = SeqClassificationReader
2020-05-05 15:06:27,300 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.dataset_reader.SeqClassificationReader'> from params {'lazy': False, 'max_sent_per_example': '3', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '90', 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'pretrained_models/news_roberta_base/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()
2020-05-05 15:06:27,300 - INFO - allennlp.common.params - dataset_reader.lazy = False
2020-05-05 15:06:27,300 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'pretrained_models/news_roberta_base/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()
2020-05-05 15:06:27,300 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2020-05-05 15:06:27,300 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'pretrained_models/news_roberta_base/vocab.txt', 'use_starting_offsets': False} and extras set()
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = pretrained_models/news_roberta_base/vocab.txt
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2020-05-05 15:06:27,301 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = True
2020-05-05 15:06:27,301 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file pretrained_models/news_roberta_base/vocab.txt
2020-05-05 15:06:27,356 - INFO - allennlp.common.params - dataset_reader.word_splitter = bert-basic
2020-05-05 15:06:27,356 - INFO - allennlp.common.registrable - instantiating registered subclass bert-basic of <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'>
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.sent_max_len = 90
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.max_sent_per_example = 3
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.use_sep = true
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.sci_sum = False
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.use_abstract_scores = False
2020-05-05 15:06:27,357 - INFO - allennlp.common.params - dataset_reader.sci_sum_fake_scores = False
2020-05-05 15:06:27,358 - INFO - allennlp.common.params - dataset_reader.predict = False
2020-05-05 15:06:27,532 - INFO - allennlp.common.params - train_data_path = data/basil/1_train_ssc.jsonl
2020-05-05 15:06:27,532 - INFO - allennlp.training.util - Reading training data from data/basil/1_train_ssc.jsonl
2020-05-05 15:06:31,589 - INFO - allennlp.common.params - validation_data_path = data/basil/1_dev_ssc.jsonl
2020-05-05 15:06:31,589 - INFO - allennlp.training.util - Reading validation data from data/basil/1_dev_ssc.jsonl
2020-05-05 15:06:32,086 - INFO - allennlp.common.params - test_data_path = data/basil/1_test_ssc.jsonl
2020-05-05 15:06:32,086 - INFO - allennlp.training.util - Reading test data from data/basil/1_test_ssc.jsonl
2020-05-05 15:06:32,486 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, validation, train will be considered for vocabulary creation.
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.type = None
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.extend = False
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.directory_path = None
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.min_count = None
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}
2020-05-05 15:06:32,486 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2020-05-05 15:06:32,487 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2020-05-05 15:06:32,487 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2020-05-05 15:06:32,487 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2020-05-05 15:06:32,539 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'pretrained_models/news_roberta_base/pytorch_model.bin', 'requires_grad': True, 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'type': 'SeqClassificationModel', 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}
2020-05-05 15:06:32,539 - INFO - allennlp.common.params - model.type = SeqClassificationModel
2020-05-05 15:06:32,539 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.model.SeqClassificationModel'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'pretrained_models/news_roberta_base/pytorch_model.bin', 'requires_grad': True, 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}
2020-05-05 15:06:32,540 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'pretrained_models/news_roberta_base/pytorch_model.bin', 'requires_grad': True, 'top_layer_only': False, 'type': 'bert-pretrained'}}} and extras {'vocab'}
2020-05-05 15:06:32,540 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2020-05-05 15:06:32,540 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2020-05-05 15:06:32,540 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'pretrained_models/news_roberta_base/pytorch_model.bin', 'requires_grad': True, 'top_layer_only': False, 'type': 'bert-pretrained'} and extras {'vocab'}
2020-05-05 15:06:32,540 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = bert-pretrained
2020-05-05 15:06:32,540 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'pretrained_models/news_roberta_base/pytorch_model.bin', 'requires_grad': True, 'top_layer_only': False} and extras {'vocab'}
2020-05-05 15:06:32,540 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = pretrained_models/news_roberta_base/pytorch_model.bin
2020-05-05 15:06:32,541 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = True
2020-05-05 15:06:32,541 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.top_layer_only = False
2020-05-05 15:06:32,541 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.scalar_mix_parameters = None
2020-05-05 15:06:32,541 - INFO - pytorch_pretrained_bert.modeling - loading archive file pretrained_models/news_roberta_base/pytorch_model.bin
2020-05-05 15:06:32,543 - INFO - pytorch_pretrained_bert.modeling - extracting archive file pretrained_models/news_roberta_base/pytorch_model.bin to temp dir /var/folders/s0/015n78c544l93860n29z_q4h0000gp/T/tmpq955kzde
