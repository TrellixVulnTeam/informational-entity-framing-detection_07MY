2020-04-22 10:23:04,062 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sent_per_example': '5', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '20', 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased-vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'type': 'SeqClassificationReader', 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras {}
2020-04-22 10:23:04,062 - INFO - allennlp.common.params - dataset_reader.type = SeqClassificationReader
2020-04-22 10:23:04,062 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.dataset_reader.SeqClassificationReader'> from params {'lazy': False, 'max_sent_per_example': '5', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '20', 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased-vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras {}
2020-04-22 10:23:04,062 - INFO - allennlp.common.params - dataset_reader.lazy = False
2020-04-22 10:23:04,062 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased-vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras {}
2020-04-22 10:23:04,062 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2020-04-22 10:23:04,063 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased-vocab.txt', 'use_starting_offsets': False} and extras {}
2020-04-22 10:23:04,063 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased-vocab.txt
2020-04-22 10:23:04,063 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False
2020-04-22 10:23:04,063 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2020-04-22 10:23:04,063 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2020-04-22 10:23:04,063 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2020-04-22 10:23:04,063 - ERROR - pytorch_pretrained_bert.tokenization - Model name 'bert-base-uncased-vocab.txt' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'bert-base-uncased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.
